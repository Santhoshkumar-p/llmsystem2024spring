| Dates | Topic                                                                                      | Reading/Content                                                                                                                                                                                                           | Homework                                                             |
| ----- | ------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------- |
| 1/17  | Introduction to LLM [[slides]](/slides/llmsys-01-intro.pdf)                                |                                                                                                                                                                                                                           | [HW1 out](/assignments/11868_LLM_Systems_Assignment_1.pdf)           |
| 1/22  | GPU Programming Basics [[slides]](/slides/llmsys-02-hw-comp.pdf)                           | Chap 2,3 of [Programming Massively Parallel Processors, 3rd Ed](https://cmu.primo.exlibrisgroup.com/permalink/01CMU_INST/6lpsnm/alma991019904889504436)                                                                   |                                                                      |
|       | Learning algorithm and Auto Differentiation  [[slides]](/slides/llmsys-03-autodiff.pdf)    | [Auto Diff survery](https://arxiv.org/abs/1502.05767)                                                                                                                                                                     |                                                                      |
| 1/29  | Deep Learning Frameworks Design Principles  [[slides]](/slides/llmsys-04-dl-framework.pdf) | [Tensorflow](https://www.usenix.org/system/files/conference/osdi16/osdi16-abadi.pdf)                                                                                                                                      |                                                                      |
|       | Transformer [[slides]](/slides/llmsys-05-transformer.pdf)                                  | [Attention is all you need](https://arxiv.org/abs/1706.03762)                                                                                                                                                             |                                                                      |
| 2/5   | Pre-trained LLMs [[slides]](/slides/llmsys-06-llms.pdf)                                    | [LLaMA](https://arxiv.org/abs/2302.13971), [GPT3](https://arxiv.org/abs/2005.14165), [Annotated Transformer](https://nlp.seas.harvard.edu/annotated-transformer/)                                                         | HW1 due / [HW2 out](/assignments/11868_LLM_Systems___Assignment_2.pdf) |
|       | Tokenization and Decoding [[slides]](/slides/llmsys-07-decoding.pdf)                       | [BPE](https://aclanthology.org/P16-1162/), [Sentence-Piece](https://aclanthology.org/D18-2012/), Top-k sampling, Beam search, Diverse bean search, Constrained Generation                                                 |                                                                      |
| 2/12  | GPU Acceleration [[slides]](/slides/llmsys-08-gpu-acceleration.pdf)                        | Chap 4,5 of [Programming Massively Parallel Processors, 3rd Ed](https://cmu.primo.exlibrisgroup.com/permalink/01CMU_INST/6lpsnm/alma991019904889504436)                                                                   |                                                                      |
|       | Accelerating Transformer on GPU Part 1 [[slides]](/slides/llmsys-09-transformer-acc.pdf)   | [LightSeq](https://arxiv.org/abs/2010.13887)                                                                                                                                                                              |                                                                      |
| 2/19  | Accelerating Transformer on GPU Part 2 [[slides]](/slides/llmsys-09-transformer-acc.pdf)   | [LightSeq2](https://arxiv.org/abs/2110.05722)                                                                                                                                                                             |                                                                      |
|       | Distributed Model Training [[slides]](/slides/llmsys-11-distributed-training.pdf)          | [DDP](https://www.vldb.org/pvldb/vol13/p3005-li.pdf)                                                                                                                                                                      | HW2 due, [HW3 out](/assignments/11868_Assignment_3.pdf)                                                              |
| 2/26  | Distributed Model Training II [[slides]](/slides/llmsys-11-distributed-training2.pdf)      | [GPipe](https://arxiv.org/abs/1811.06965), [Megatron-LM](https://arxiv.org/abs/2104.04473)                                                                                                                                |                                                                      |
|       | Model Serving Service and GPU Inference Frameworks                                         | [Triton](https://www.eecs.harvard.edu/~htk/publication/2019-mapl-tillet-kung-cox.pdf), [Tutorial](https://triton-lang.org/main/index.html),  ([LightLLM](https://github.com/ModelTC/lightllm/blob/main/docs/LightLLM.md)) | Project proposal due                                                 |
| 3/4   | spring break                                                                               |                                                                                                                                                                                                                           |                                                                      |
| 3/11  | Model Quantization and Compression                                                         | [GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers](https://arxiv.org/abs/2210.17323)                                                                                                     | HW3 due                                                              |
|       | Efficient fine-tuning for Large Models                                                     | [LORA](https://arxiv.org/abs/2106.09685), [QLoRA](https://arxiv.org/abs/2305.14314)                                                                                                                                       |                                                                      |
| 3/18  | Communication Efficient Distributed Training, popular frameworks                           | [ZeRO: Memory Optimizations Toward Training Trillion Parameter Models ](https://arxiv.org/pdf/1910.02054.pdf)(DeepSpeed)                                                                                                  |                                                                      |
|       | Advanced Large Model Serving and GPU Inference frameworks                                  | [Orca: A Distributed Serving System for Transformer-Based Generative Models](https://www.usenix.org/conference/osdi22/presentation/yu)                                                                                    |                                                                      |
| 3/25  | PageAttention                                                                              | [vLLM:](https://blog.vllm.ai/2023/06/20/vllm.html)[ Easy, Fast, and Cheap LLM Serving with PagedAttention](https://blog.vllm.ai/2023/06/20/vllm.html)                                                                     | HW4 due                                                              |
|       | GPU just-in-time compilation                                                               | [Compiling machine learning programs via high-level tracing (JAX)](https://mlsys.org/Conferences/doc/2018/146.pdf)                                                                                                        |                                                                      |
| 4/1   | Large models, Sparse Routing, Mixture-of-Expert, and Multiway Networks                     | [DeepSpeed-MOE](https://arxiv.org/pdf/2201.05596.pdf)                                                                                                                                                                     | Mid-term report due                                                  |
|       | Efficient Attention and Memory Optimization for LLMs                                       | [FlashAttention](https://arxiv.org/pdf/2205.14135.pdf)                                                                                                                                                                    |                                                                      |
| 4/8   | Longe Context and Extremely Long Sequence Generation                                       | [Scaling Transformer to 1M tokens and beyond with RMT](https://arxiv.org/pdf/2304.11062.pdf)                                                                                                                              | HW5 due                                                              |
|       | Efficient Streaming Language Models with Attention Sinks                                   | [Attention Sink](https://arxiv.org/abs/2309.17453)                                                                                                                                                                        |                                                                      |
| 4/15  | Speculative Decoding                                                                       | [Fast Inference from Transformers via Speculative Decoding](https://arxiv.org/abs/2211.17192)                                                                                                                             |                                                                      |
|       | Efficient Vector Database and Retrieval-augmented Language Models                          | Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks                                                                                                                                                          |                                                                      |
| 4/22  | Nearest Vector Search for Embeddings                                                       | Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs                                                                                                                  |                                                                      |
|       | Multimodal LLMs (visual language and speech language)                                      | [Flamingo: a Visual Language Model for Few-Shot Learning](https://arxiv.org/abs/2204.14198)  ([shorter version](https://openreview.net/pdf?id=EbMuimAbPbs))                                                               |                                                                      |
| 4/29  | Final project presentation                                                                 |                                                                                                                                                                                                                           |                                                                      |
| 4/30  |                                                                                            |                                                                                                                                                                                                                           | Final report due                                                     |
