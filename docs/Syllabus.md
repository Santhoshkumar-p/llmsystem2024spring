
[Link to preliminary syllabus](https://drive.google.com/file/d/1wvN2CrHQmuTiFZaETUwLWtwI5fTMbOJy/view)

| Dates             | Topic                                                        |
| ----------------- | ------------------------------------------------------------ |
| 1/15              | Introduction and ML/LLM BasicsTransformer                    |
|                   | Transformer                                                  |
| 1/22              | GPT and LLMs, use cases and challenges                       |
|                   | Deep Learning Frameworks and Design Principles               |
| 1/29              | GPU Computation and memory management basics.                |
|                   | Low-level Computation for Tensor Operators, Verifying and Visualizing Results |
| 2/5               | Fast Tokenization and Embeddings, Vocabulary Optimization    |
|                   | Learning and Optimization algorithms                         |
| 2/12              | Implementing Transformer Forward and Back-propagation in CUDA |
|                   | GPU Acceleration via Kernel Fusion                           |
| 2/19              | Decoding - sampling & beam search                            |
|                   | Efficient Sequence Decoding on GPU                           |
| 2/26              | Model Serving Service and GPU Inference Frameworks           |
|                   | GPU just-in-time compilation                                 |
| 3/4               | Spring Break                                                 |
| 3/11              | Large models, Sparse Routing, Mixture-of-Expert, and Multiway Networks |
|                   | Distributed Model Training                                   |
| 3/18              | Communication Efficient Distributed Training, popular frameworks |
|                   | Efficient fine-tuning for Large Models                       |
| 3/25              | Efficient Attention and Memory Optimization for LLMs         |
|                   | Advanced Large Model Serving and GPU Inference frameworks    |
| 4/1               | CPU based Serving                                            |
|                   | Efficient Vector Database and Retrieval-augmented Language Models |
| 4/8               | Nearest Vector Search for Embeddings                         |
|                   | LLM Operation and Monitor Tools                              |
| 4/15              | Longe Context and Extremely Long Sequence Generation         |
|                   | Model Quantization and Compression                           |
| 4/22              | Data Mining, Cleaning, Deduplication, Auditing, and Safeguard for LLMs |
|                   | Multimodal LLMs (visual language and speech language)        |
| 4/28              | Final project presentationc                                  |
| Additional Topics |                                                              |
|                   | Privacy, Authenticity, Safety Systems of LLMs                |
|                   | Copyright Protection for LLM                                 |
|                   | Case Study: LLAMA2 and GPT4                                  |
