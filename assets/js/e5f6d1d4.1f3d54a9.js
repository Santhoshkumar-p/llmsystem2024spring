"use strict";(self.webpackChunkllmsystem=self.webpackChunkllmsystem||[]).push([[784],{3213:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>a,contentTitle:()=>i,default:()=>h,frontMatter:()=>d,metadata:()=>l,toc:()=>c});var r=n(5893),s=n(1151);const d={},i=void 0,l={id:"Syllabus",title:"Syllabus",description:"Link to preliminary syllabus",source:"@site/docs/Syllabus.md",sourceDirName:".",slug:"/Syllabus",permalink:"/llmsystem2024spring/docs/Syllabus",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{}},a={},c=[];function o(e){const t={a:"a",p:"p",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,s.a)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.p,{children:(0,r.jsx)(t.a,{href:"https://drive.google.com/file/d/1wvN2CrHQmuTiFZaETUwLWtwI5fTMbOJy/view",children:"Link to preliminary syllabus"})}),"\n",(0,r.jsxs)(t.table,{children:[(0,r.jsx)(t.thead,{children:(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.th,{children:"Dates"}),(0,r.jsx)(t.th,{children:"Topic"}),(0,r.jsx)(t.th,{children:"Reading/Content"}),(0,r.jsx)(t.th,{children:"Homework"})]})}),(0,r.jsxs)(t.tbody,{children:[(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"1/17"}),(0,r.jsx)(t.td,{children:"Introduction to LLM"}),(0,r.jsx)(t.td,{}),(0,r.jsx)(t.td,{})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"1/22"}),(0,r.jsx)(t.td,{children:"GPU Programming Basics"}),(0,r.jsx)(t.td,{children:"Low-level storage and computation for data and tensors, matrix computation on gpu"}),(0,r.jsx)(t.td,{})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{}),(0,r.jsx)(t.td,{children:"Learning algorithm and Auto Differentiation"}),(0,r.jsx)(t.td,{}),(0,r.jsx)(t.td,{})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"1/29"}),(0,r.jsx)(t.td,{children:"Deep Learning Frameworks Design Principles"}),(0,r.jsx)(t.td,{children:"Tensorflow, Pytorch paper"}),(0,r.jsx)(t.td,{})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{}),(0,r.jsx)(t.td,{children:"Transformer"}),(0,r.jsx)(t.td,{children:"Attention is all you need, Annotated Transformer"}),(0,r.jsx)(t.td,{})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"2/5"}),(0,r.jsx)(t.td,{children:"Fast Tokenization and Embeddings"}),(0,r.jsx)(t.td,{children:"BPE, Sentence-Piece, Word-piece, Token and Positional Embeddings."}),(0,r.jsx)(t.td,{children:"HW 1 due"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{}),(0,r.jsx)(t.td,{children:"Decoding - sampling & beam search"}),(0,r.jsx)(t.td,{children:"Top-k sampling, Beam search, Diverse bean search, Constrained Generation"}),(0,r.jsx)(t.td,{})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"2/12"}),(0,r.jsx)(t.td,{children:"GPU Architecture for DL"}),(0,r.jsx)(t.td,{children:"basic introduction of A100/H100 GPU"}),(0,r.jsx)(t.td,{children:"Guest(?)"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{}),(0,r.jsx)(t.td,{children:"GPU Acceleration 1"}),(0,r.jsx)(t.td,{children:"LightSeq"}),(0,r.jsx)(t.td,{})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"2/19"}),(0,r.jsx)(t.td,{children:"Efficient Sequence Decoding on GPU"}),(0,r.jsx)(t.td,{children:"LightSeq, FlexGen"}),(0,r.jsx)(t.td,{children:"HW2 due"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{}),(0,r.jsx)(t.td,{children:"Accelerating Backward Computation on GPU"}),(0,r.jsx)(t.td,{}),(0,r.jsx)(t.td,{})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"2/26"}),(0,r.jsx)(t.td,{children:"Distributed Model Training"}),(0,r.jsx)(t.td,{children:"PyTorch FSDP, Pytorch notebook implementations, Stabilizing LLM training"}),(0,r.jsx)(t.td,{})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{}),(0,r.jsx)(t.td,{children:"Communication Efficient Distributed Training, popular frameworks"}),(0,r.jsx)(t.td,{children:"DeepSpeed, gpt-neox, megatron"}),(0,r.jsx)(t.td,{})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"3/4"}),(0,r.jsx)(t.td,{children:"spring break"}),(0,r.jsx)(t.td,{}),(0,r.jsx)(t.td,{})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"3/11"}),(0,r.jsx)(t.td,{children:"Model Quantization and Compression"}),(0,r.jsx)(t.td,{children:"GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers"}),(0,r.jsx)(t.td,{children:"HW3 Due"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{}),(0,r.jsx)(t.td,{children:"Efficient fine-tuning for Large Models"}),(0,r.jsx)(t.td,{children:"LORA, QLoRA, gradient checkpoint"}),(0,r.jsx)(t.td,{})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"3/18"}),(0,r.jsx)(t.td,{children:"Model Serving Service and GPU Inference Frameworks"}),(0,r.jsx)(t.td,{children:"LightLLM and Triton"}),(0,r.jsx)(t.td,{})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{}),(0,r.jsx)(t.td,{children:"CPU based Serving, LLM Operation and Monitor"}),(0,r.jsxs)(t.td,{children:["gglm, llama.cpp, MLC, ",(0,r.jsx)(t.a,{href:"https://github.com/tensorchord/Awesome-LLMOps",children:"https://github.com/tensorchord/Awesome-LLMOps"})]}),(0,r.jsx)(t.td,{})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"3/25"}),(0,r.jsx)(t.td,{children:"Advanced Large Model Serving and GPU Inference frameworks"}),(0,r.jsx)(t.td,{children:"Orca: A Distributed Serving System for Transformer-Based Generative Models"}),(0,r.jsx)(t.td,{children:"HW4 Due"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{}),(0,r.jsx)(t.td,{children:"PageAttention"}),(0,r.jsx)(t.td,{children:"vLLM:\xa0Easy, Fast, and Cheap LLM Serving with PagedAttention, AlpaServe"}),(0,r.jsx)(t.td,{})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"4/1"}),(0,r.jsx)(t.td,{children:"GPU just-in-time compilation"}),(0,r.jsx)(t.td,{children:"Compiling machine learning programs via high-level tracing (JAX)"}),(0,r.jsx)(t.td,{})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{}),(0,r.jsx)(t.td,{children:"Large models, Sparse Routing, Mixture-of-Expert, and Multiway Networks"}),(0,r.jsx)(t.td,{children:"Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer, GShard, DeepSpeed-MOE, Tutul"}),(0,r.jsx)(t.td,{})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"4/8"}),(0,r.jsx)(t.td,{children:"Efficient Attention and Memory Optimization for LLMs"}),(0,r.jsx)(t.td,{children:"FlashAttention, Multi-query Attention, ZeRO"}),(0,r.jsx)(t.td,{children:"HW5 Due"})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{}),(0,r.jsx)(t.td,{children:"Longe Context and Extremely Long Sequence Generation"}),(0,r.jsx)(t.td,{children:"Rethinking Attention with Performers, Blockwise Parallel Transformer for Large Context Models, Scaling Transformer to 1M tokens and beyond with RMT"}),(0,r.jsx)(t.td,{})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"4/15"}),(0,r.jsx)(t.td,{children:"Efficient Vector Database and Retrieval-augmented Language Models"}),(0,r.jsx)(t.td,{children:"REALM: Retrieval-Augmented Language Model Pre-Training, Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"}),(0,r.jsx)(t.td,{})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{}),(0,r.jsx)(t.td,{children:"Nearest Vector Search for Embeddings"}),(0,r.jsx)(t.td,{children:"Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs, Filtered \u2212 DiskANN: Graph Algorithms for Approximate Nearest Neighbor Search with Filters, Accelerating Large-Scale Inference with Anisotropic Vector Quantization"}),(0,r.jsx)(t.td,{})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"4/22"}),(0,r.jsx)(t.td,{children:"Speculative Decoding"}),(0,r.jsx)(t.td,{children:"Fast Inference from Transformers via Speculative Decoding; Accelerating Large Language Model Decoding"}),(0,r.jsx)(t.td,{})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"with Speculative Sampling"}),(0,r.jsx)(t.td,{}),(0,r.jsx)(t.td,{}),(0,r.jsx)(t.td,{})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{}),(0,r.jsx)(t.td,{children:"Multimodal LLMs (visual language and speech language)"}),(0,r.jsx)(t.td,{children:"Flamingo: a Visual Language Model for Few-Shot Learning, SeamlessM4T\u2014Massively Multilingual & Multimodal Machine Translation"}),(0,r.jsx)(t.td,{})]}),(0,r.jsxs)(t.tr,{children:[(0,r.jsx)(t.td,{children:"4/28"}),(0,r.jsx)(t.td,{children:"Final project presentation"}),(0,r.jsx)(t.td,{}),(0,r.jsx)(t.td,{})]})]})]})]})}function h(e={}){const{wrapper:t}={...(0,s.a)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(o,{...e})}):o(e)}},1151:(e,t,n)=>{n.d(t,{Z:()=>l,a:()=>i});var r=n(7294);const s={},d=r.createContext(s);function i(e){const t=r.useContext(d);return r.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function l(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),r.createElement(d.Provider,{value:t},e.children)}}}]);